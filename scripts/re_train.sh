#!/bin/bash

# é‡æ–°å¼€å§‹è®­ç»ƒè„šæœ¬
# é€‚ç”¨äºVAST AI GPUç¯å¢ƒ

set -e

echo "=========================================="
echo "é‡æ–°å¼€å§‹è®­ç»ƒï¼ˆå®Œå…¨ä»å¤´å¼€å§‹ï¼‰"
echo "=========================================="

# è®¾ç½®ç¯å¢ƒå˜é‡
export TOKENIZERS_PARALLELISM=false
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# è·å–å‚æ•°
MAX_STEPS=${1:-1000}
RESET_CHECKPOINTS=${2:-false}

echo "æœ€å¤§æ­¥æ•°: $MAX_STEPS"
echo "é‡ç½®æ£€æŸ¥ç‚¹: $RESET_CHECKPOINTS"
echo ""

# è®¾ç½®ç¯å¢ƒå˜é‡
echo "æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi || echo "âš ï¸  nvidia-smiä¸å¯ç”¨"
NUM_GPUS=$(nvidia-smi --list-gpus 2>/dev/null | wc -l || echo "0")
echo "æ£€æµ‹åˆ° $NUM_GPUS ä¸ªGPU"

if [ "$NUM_GPUS" -ge 4 ]; then
    export CUDA_VISIBLE_DEVICES=0,1,2,3
    echo "âœ… ä½¿ç”¨4Ã—GPUé…ç½®"
elif [ "$NUM_GPUS" -ge 2 ]; then
    export CUDA_VISIBLE_DEVICES=0,1
    echo "âœ… ä½¿ç”¨2Ã—GPUé…ç½®"
elif [ "$NUM_GPUS" -eq 1 ]; then
    export CUDA_VISIBLE_DEVICES=0
    echo "âš ï¸  ä»…ä½¿ç”¨1ä¸ªGPU"
else
    echo "âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤é…ç½®"
fi

# å¦‚æœè¦æ±‚é‡ç½®æ£€æŸ¥ç‚¹
if [ "$RESET_CHECKPOINTS" = "true" ]; then
    echo ""
    read -p "âš ï¸  è¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰æ£€æŸ¥ç‚¹ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/n) " -n 1 -r
    echo ""
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "ğŸ—‘ï¸  åˆ é™¤ç°æœ‰æ£€æŸ¥ç‚¹..."
        rm -rf ./checkpoints/rl_model/checkpoint-*
        echo "âœ… æ£€æŸ¥ç‚¹å·²åˆ é™¤"
    else
        echo "âŒ æ“ä½œå·²å–æ¶ˆ"
        exit 0
    fi
fi

# å¼€å§‹æ–°è®­ç»ƒ
echo ""
echo "ğŸ”„ å¼€å§‹æ–°çš„è®­ç»ƒ..."
python scripts/train_rl.py \
    --config config/training_config.yaml \
    --student_model_path ./checkpoints/sft_model \
    --output_dir ./checkpoints/rl_model \
    --max_steps $MAX_STEPS \
    --log_level INFO

echo "âœ… è®­ç»ƒå®Œæˆ"

